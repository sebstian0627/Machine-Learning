{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "As1Ka4pf_q3U"
      },
      "outputs": [],
      "source": [
        "#IMPORTS\n",
        "import random\n",
        "import csv\n",
        "import heapq\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "from glob import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHbwITLN_t8D"
      },
      "outputs": [],
      "source": [
        "# #QUESTION 1 DATA READ AND NORMALIZE \n",
        "data_tr=[]\n",
        "data_tt=[]\n",
        "\n",
        "#READS DATA \n",
        "with open('health_data.csv','r') as file:\n",
        "  csvf= csv.DictReader(file)\n",
        "  data=[]\n",
        "  for row in csvf:\n",
        "    data.append(row)\n",
        " \n",
        "  ll=random.sample(range(700),490)\n",
        "  for i in range(700):\n",
        "    if i in ll:\n",
        "      data_tr.append([int(x) for x in data[i].values()])\n",
        "    else:\n",
        "      data_tt.append([int(x) for x in data[i].values()])\n",
        "  \n",
        "data_ttt = np.array(data_tt) \n",
        "data_trr = np.array(data_tr)\n",
        "\n",
        "#NORMALIZATION DATA\n",
        "\n",
        "normalize  = np.zeros((len(data_ttt[0])-1))\n",
        "data_tr=dict()\n",
        "data_tt=dict()\n",
        "possible_outcomes = set()\n",
        "for i in data_ttt:\n",
        "  possible_outcomes.add(i[len(i)-1])\n",
        "  for j in range(len(i)-1):\n",
        "    if normalize[j] < i[j]:\n",
        "      normalize[j] = i[j]\n",
        "for i in possible_outcomes:\n",
        "  data_tr[i] = []\n",
        "  data_tt[i] = []\n",
        "for i in data_ttt:\n",
        "  data_tt[i[len(i)-1]].append( i[:-1]/normalize  )\n",
        "\n",
        "for i in data_trr:\n",
        "  data_tr[i[len(i)-1]].append( i[:-1]/normalize )\n",
        "\n",
        "for i in possible_outcomes:\n",
        "  data_tr[i] = np.array(data_tr[i])\n",
        "  data_tt[i] = np.array(data_tt[i])\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "def sigmoid(X):\n",
        "  return 1/(1+np.exp(-1*X))\n",
        "\n",
        "def prepare_data_for_loget():\n",
        "  for i in data_tr.items():\n",
        "    for j in i[1]:\n",
        "      X.append(j)\n",
        "      y.append(i[0])\n",
        "\n",
        "#prior\n",
        "dicto = {}\n",
        "def prior():\n",
        "  nu_0=len(data_tr[0])\n",
        "  nu_1=len(data_tr[1])\n",
        "  total=nu_0+nu_1\n",
        "  p_0=nu_0/total\n",
        "  p_1=nu_1/total\n",
        "  return p_0,p_1\n",
        "dicto[0],dicto[1] = prior()\n",
        "prepare_data_for_loget()\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "# Done :D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBqBJ_GIAB_S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# fits gaussian on a given dataset\n",
        "def fit_gaussian(data_tr):\n",
        "  data_tr = np.array(data_tr)\n",
        "  return (np.reshape(np.mean(data_tr,axis=0),(3,1)),np.cov(data_tr.T,rowvar=1))\n",
        "\n",
        "# Trains Gaussian\n",
        "dict1 = {}\n",
        "for i in data_tr.items():\n",
        "  dict1[i[0]] = fit_gaussian(i[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcaBOpJMKST2",
        "outputId": "c3b10a89-1df6-4ebe-8c1e-f386047929fa"
      },
      "outputs": [],
      "source": [
        "# Evaluates Gaussian and returns its logarithm\n",
        "e = math.exp(1)\n",
        "def gaussian(x,sigma,u,n):\n",
        "  x = np.reshape(x,(len(x),1))\n",
        "  const =  1/math.sqrt( ( ((2*math.pi)**n)*abs(np.linalg.det(sigma)) ) ) \n",
        "  other_term = ((np.transpose(x-u))@(np.linalg.pinv(sigma)))@(x-u)\n",
        "  return math.log(const,e)  + -0.5*other_term\n",
        "\n",
        "# predicts label given a data point \n",
        "def predict(x,th):\n",
        "  p0 = dicto[0]*math.exp(gaussian(x,dict1[1][1],dict1[0][0],len(x)))\n",
        "  p1 = dicto[1]*math.exp(gaussian(x,dict1[1][1],dict1[1][0],len(x)))\n",
        "  if p1/p0 > th:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "    \n",
        "# evaluate model at entire test set and returns relevant results\n",
        "def check(th):\n",
        "  right = 0\n",
        "  l = 0\n",
        "  tp = 0 \n",
        "  tn = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  for i in data_tt.items():\n",
        "    for j in i[1]:\n",
        "      l+=1\n",
        "      pre = int(predict(j,th))\n",
        "      if i[0] == pre and i[0]== 1:\n",
        "        tp+=1\n",
        "        right+=1\n",
        "      elif i[0] == pre and i[0] == 0:\n",
        "        tn+=1\n",
        "        right+=1\n",
        "      elif i[0] == 1 and pre == 0:\n",
        "        fn+=1\n",
        "      elif i[0] == 0 and pre == 1:\n",
        "        fp+=1\n",
        "  prescion = tp/(tp+fp)\n",
        "  recall = tp/(tp+fn)\n",
        "  f1 = 2/(1/recall+1/prescion)\n",
        "  accuracy = right/l\n",
        "  tpr = 1\n",
        "  fpr = 1\n",
        "  if tp + fn!=0:\n",
        "    tpr = tp/(tp+fn)\n",
        "  if fp+tn!=0:\n",
        "    fpr = fp/(fp+tn)\n",
        "  return accuracy,prescion,f1,recall,tpr,fpr,tp,fp,tn,fn\n",
        "print(check(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AW9kDiGDzEu"
      },
      "outputs": [],
      "source": [
        "# creates unimodal gaussian models for a given dataset :(\n",
        "def sasta_fit_gaussian(data_tr):\n",
        "  data_tr = np.array(data_tr)\n",
        "  return np.mean(data_tr),np.var(data_tr)\n",
        "dict1 = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "mgXKL_ewpkZt",
        "outputId": "5af81c43-1ac3-4213-96e9-16078fca4822",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#naive bayes model\n",
        "e = math.exp(1)\n",
        "# evalevates unimodal gaussian \n",
        "def sasta_gaussian(x,sigma,u):\n",
        "  return (1/math.sqrt(math.pi*2*sigma))*math.exp(-0.5*((x-u)*(x-u)/sigma)) \n",
        "\n",
        "# devlaration issue reolved :(\n",
        "possible_outcomes = list(possible_outcomes)\n",
        "\n",
        "# trains navie bayes for each feature for each parameter\n",
        "def naive_bayes(data_tr):\n",
        "  n = 3\n",
        "  models = np.zeros((3,2,2))\n",
        "  for i in range(n):\n",
        "    for j in possible_outcomes:\n",
        "      models[i][j][0],models[i][j][1] = sasta_fit_gaussian( (data_tr[j].T[i]) ) \n",
        "  return models\n",
        "\n",
        "models = naive_bayes(data_tr)\n",
        "\n",
        "#Evaluates Naive bayes over entier test set and returns relevant results\n",
        "def eval(data_tt,th):\n",
        "  right = 0\n",
        "  l = 0\n",
        "  tp = 0 \n",
        "  tn = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  for i in data_tt.items():\n",
        "    for j in i[1]:\n",
        "      l+=1\n",
        "      pre = int(predict_n(j,th))\n",
        "      if i[0] == pre == 1:\n",
        "        tp+=1\n",
        "        right+=1\n",
        "      elif i[0] == pre == 0:\n",
        "        tn+=1\n",
        "        right+=1\n",
        "      elif i[0] == 1:\n",
        "        fn+=1\n",
        "      elif i[0] == 0:\n",
        "        fp+=1\n",
        "  prescion = tp/(tp+fp)\n",
        "  recall = tp/(tp+fn)\n",
        "  f1 = 2/(1/recall+1/prescion)\n",
        "  accuracy = right/l\n",
        "  tpr = tp/(tp+fn)\n",
        "  fpr = fp/(fp+tn)\n",
        "  return accuracy,prescion,f1,recall,tpr,fpr,tp,tn,fp,fn\n",
        "\n",
        "# predicts a label for a point naive bayes\n",
        "def predict_n(x,th):\n",
        "  probab = []\n",
        "  for i in range(len(possible_outcomes)):\n",
        "    temp = dicto[i]\n",
        "    for j in range(3):\n",
        "      temp*=sasta_gaussian(x[j],models[j][i][1],models[j][i][0])\n",
        "    probab.append(temp)\n",
        "  if probab[1]/probab[0]>th:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "print(eval(data_tt,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EM algoritm for GMM \n",
        "e =math.exp(1)\n",
        "def GM(data,iteration,k):\n",
        "  data = np.array(data)\n",
        "  dimension = len(data[0])\n",
        "  n = len(data)\n",
        "  pk = np.array( [1/k]*k )\n",
        "  mu = np.array( np.random.uniform(low=0.001,high=0.002, size=(k,dimension,1)) )\n",
        "  sigma = np.array( np.random.uniform(low=0.001,high=1000, size=(k,dimension,dimension)) )\n",
        "  log_liklihood = -1e18\n",
        "  for iter in range(iteration):\n",
        "    tmu = np.zeros((k,dimension,1))\n",
        "    tsigma = np.zeros((k,dimension,dimension))\n",
        "    tpk = np.zeros((k,1))\n",
        "    global_sum = 0 \n",
        "\n",
        "    dp = np.zeros((n,k))\n",
        "    new_log_liklihood = 0\n",
        "\n",
        "    #E - Step\n",
        "    for i in range(n):\n",
        "      normal = 0\n",
        "      for j in range(k):\n",
        "        oo = np.reshape(data[i],(data[i].shape[0],1))\n",
        "        dp[i][j] = pk[j]*math.exp(gaussian(oo,sigma[j],mu[j],dimension))\n",
        "        normal += dp[i][j]\n",
        "      dp[i]/=normal\n",
        "      new_log_liklihood += math.log(normal,e)\n",
        "      for j in range(k):\n",
        "        global_sum+=dp[i][j]\n",
        "        tpk[j]+=dp[i][j]\n",
        "      \n",
        "    # M - step\n",
        "    for i in range(n):\n",
        "      for j in range(k):\n",
        "        oo = np.reshape(data[i],(data[i].shape[0],1))\n",
        "        factor =  (dp[i][j]/tpk[j])\n",
        "        tmu[j] += factor*oo\n",
        "        oj = (oo-mu[j])@(np.transpose(oo-mu[j]))\n",
        "        tsigma[j] += factor*oj\n",
        "\n",
        "    for i in range(k):\n",
        "      tpk[i]/=global_sum\n",
        "\n",
        "    #Exchange \n",
        "    pk = tpk.copy()\n",
        "    sigma = tsigma.copy()\n",
        "    mu = tmu.copy()\n",
        "    if abs(new_log_liklihood-log_liklihood)<1e-6:\n",
        "      break\n",
        "    \n",
        "    log_liklihood = new_log_liklihood\n",
        "  return [pk,mu,sigma]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHlQgVoNBK5L",
        "outputId": "462571f5-999a-4944-de1f-da267cef1139"
      },
      "outputs": [],
      "source": [
        "#trains GMM model\n",
        "pp = dict()\n",
        "def gmmtrain(k):\n",
        "    global pp\n",
        "    pp = dict()\n",
        "    for i in data_tr.items():\n",
        "        pp[i[0]] = GM(i[1],10000,k)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# predicts a label of a point using gmm\n",
        "def predict_gmm(x,k,th):\n",
        "  probab = []\n",
        "  for i in pp.items():\n",
        "    sum = 0\n",
        "    for j in range(k):\n",
        "      sum += i[1][0][j]*math.exp(gaussian(x,i[1][2][j],i[1][1][j],len(x)))\n",
        "    probab.append(dicto[i[0]]*sum)\n",
        "  if probab[1]/probab[0] > th:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# evalueavtes GMM over all test set\n",
        "def check_gmm(k,th):\n",
        "  right = 0\n",
        "  right2 = 0\n",
        "  l = 0\n",
        "  l2 = 0\n",
        "  tp = 0 \n",
        "  tn = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  for i in data_tr.items():\n",
        "    for j in i[1]:\n",
        "      l2+=1\n",
        "      pre = int(predict_gmm(j,k,th))\n",
        "      if i[0] == pre:\n",
        "        right2+=1\n",
        "    \n",
        "  for i in data_tt.items():\n",
        "    for j in i[1]:\n",
        "      l+=1\n",
        "      pre = int(predict_gmm(j,k,th))\n",
        "      if i[0] == pre == 1:\n",
        "        tp+=1\n",
        "        right+=1\n",
        "      elif i[0] == pre == 0:\n",
        "        tn+=1\n",
        "        right+=1\n",
        "      elif i[0] == 1:\n",
        "        fp+=1\n",
        "      elif i[0] == 0:\n",
        "        fn+=1\n",
        "  prescion = tp/(tp+fp)\n",
        "  recall = tp/(tp+fn)\n",
        "  f1 = 2/(1/recall+1/prescion)\n",
        "  accuracy = right/l\n",
        "  tpr = tp/(tp+fn)\n",
        "  fpr = fp/(fp+tn)\n",
        "  train_loss = right2/l2\n",
        "  return accuracy,prescion,f1,recall,tpr,fpr,train_loss,tp,tn,fp,fn\n",
        "gmmtrain(1)\n",
        "print(check_gmm(1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#GENERAL KNN \n",
        "\n",
        "def distance(a,b):\n",
        "  return (int(a)-int(b))*(int(a)-int(b))\n",
        "\n",
        "# predicts label using knn model given test data,point,k and threshhold\n",
        "def knn(data,point,k,th): \n",
        "  n = len(data)\n",
        "  o = len(point)\n",
        "  heap = []\n",
        "  for i in range(n):\n",
        "    dist = 0\n",
        "    for j in range(o):\n",
        "      dist += distance(data[i][j],point[j])\n",
        "    heap.append((dist,data[i][o]))\n",
        "  heapq.heapify(heap)\n",
        "  probab = [0,0]\n",
        "  for i in range(k):\n",
        "    temp = heapq.heappop(heap)[1]\n",
        "    probab[temp]+=1\n",
        "  if probab[0]==0 or probab[1]/probab[0] > th:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# evalueavtes knn over all test set\n",
        "def knn_caller(data,test,k,th):\n",
        "  n = len(test)\n",
        "  o = len(data[0])\n",
        "  tp = 0\n",
        "  tn = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  right = 0\n",
        "  for i in range(n):\n",
        "    lis = []\n",
        "    for j in range(o-1):\n",
        "      lis.append(test[i][j])\n",
        "    temp = knn(data,lis,k,th)\n",
        "    if temp==test[i][o-1]:\n",
        "      right+=1\n",
        "    if temp==1 and test[i][o-1]==1:\n",
        "      tp+=1\n",
        "    elif temp==0 and test[i][o-1]==0:\n",
        "      tn+=1\n",
        "    elif temp!=0 and test[i][o-1]==0:\n",
        "      fn+=1\n",
        "    else:\n",
        "      fp+=1\n",
        "  prescion = tp/(tp+fp)\n",
        "  recall = tp/(tp+fn)\n",
        "  f1 = 2/(1/recall+1/prescion)\n",
        "  accuracy = right/n\n",
        "  tpr = 1\n",
        "  fpr = 1 \n",
        "  if tp + fn != 0: \n",
        "    tpr = tp/(tp+fn)\n",
        "  if tp + fn != 0:\n",
        "    fpr = fp/(fp+tn)\n",
        "  return accuracy,prescion,f1,recall,tpr,fpr,tp,tn,fn,fp\n",
        "print(knn_caller(data_trr,data_ttt,40,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#GENERAL PARZEN WINDOW \n",
        "# checks if point2 lies in window around point\n",
        "def valid(point,point2,parameter):\n",
        "  n = len(parameter)\n",
        "  for i in range(n):\n",
        "    if abs(int(point2[i]) - int(point[i]))/parameter[i] > 0.5:\n",
        "      return 0\n",
        "  return 1\n",
        "\n",
        "# Returns label for point given train data(Data) and window size (Parameter)\n",
        "def parzen(data,point,parameter,th): \n",
        "  n = len(data)\n",
        "  o = len(parameter)\n",
        "  probab = [0,0]\n",
        "  for i in range(n):\n",
        "    probab[data[i][o]]+=valid(point,data[i],parameter)\n",
        "  if probab[0]==0 or probab[1]/probab[0] > th:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "#Evaluates over entire test set and returns the result parameters\n",
        "def parzen_caller(data,test,parameter,th):\n",
        "  n = len(test)\n",
        "  o = len(data[0])\n",
        "  tp = 0\n",
        "  tn = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  right = 0\n",
        "  for i in range(n):\n",
        "    temp = parzen(data,test[i],parameter,th)\n",
        "    if temp==test[i][o-1]:\n",
        "      right+=1\n",
        "    if temp==1 and test[i][o-1]==1:\n",
        "      tp+=1\n",
        "    elif temp==0 and test[i][o-1]==0:\n",
        "      tn+=1\n",
        "    elif temp!=0 and test[i][o-1]==0:\n",
        "      fn+=1\n",
        "    else:\n",
        "      fp+=1\n",
        "  prescion = tp/(tp+fp)\n",
        "  recall = tp/(tp+fn)\n",
        "  f1 = 2/(1/recall+1/prescion)\n",
        "  accuracy = right/n\n",
        "  tpr = tp/(tp+fn)\n",
        "  fpr = fp/(fp+tn)\n",
        "  return accuracy,prescion,f1,recall,tpr,fpr,tp,tn,fn,fp\n",
        "parzen_caller(data_trr,data_ttt,[43,43,43],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEU9nv8MamPK",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#---------------------------Linear kernel-----------------------------------------\n",
        "# Genearates Nth order terms for a given order\n",
        "lisss=['1','2','3']\n",
        "def kernel(data,order):\n",
        "  term_vec = kernel_gen(lisss,order)\n",
        "  aa=np.array(data)\n",
        "  kernel_data=[]\n",
        "  dataT=aa.T\n",
        "  for i in term_vec:\n",
        "    c=dataT[int(i[0])-1]\n",
        "    for j in range(1,len(i)):\n",
        "      c=c*dataT[int(i[j])-1]\n",
        "    kernel_data.append(c)\n",
        "  return np.array(kernel_data).T\n",
        "\n",
        "def kernel_gen(parameter,order):\n",
        "  lis = ['']\n",
        "  for iter in range(order):\n",
        "    lis_2 = []\n",
        "    for j in parameter:\n",
        "      for k in lis:\n",
        "        lis_2.append(k+j)\n",
        "    for i in lis_2:\n",
        "      ss=[]\n",
        "      ss[:0]=i \n",
        "      ss.sort()\n",
        "      ss=\"\".join(ss)\n",
        "      if ss not in lis:\n",
        "        lis.append(ss)\n",
        "  lis = lis[1:]\n",
        "  return lis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def linear_regr_reg_MAE_elasNet_vectorized(X,y,alpha,lambda1,lambda2,max_iter=10000):\n",
        "  m,n=X.shape\n",
        "  W=np.array( np.random.uniform(low=0.001,high=1, size=(X[0].shape[0],1)) )\n",
        "  w_0=0\n",
        "  y =  np.reshape(y,(y.shape[0],1))\n",
        "  W=np.reshape(W,(n,1))\n",
        "  for xxxxx in range(max_iter):\n",
        "    Y_p=X.dot(W)+w_0\n",
        "    # print(W.shape,Y_p.shape)\n",
        "    Y_p=np.reshape(Y_p,(Y_p.shape[0],1))\n",
        "    grad_W=np.zeros((n,1))\n",
        "    grad_w_0=np.sum(np.where(Y_p-y>0,1,-1))/m\n",
        "    ww=np.where(W>0,lambda1,-lambda1)\n",
        "    # print(ww.shape)\n",
        "    XX=np.where(Y_p-y>0,np.abs(X),-np.abs(X))\n",
        "    grad_W=(np.reshape(np.sum(XX,axis=0),(n,1))+ww+2*lambda2*W)/m\n",
        "    W=W-alpha*grad_W\n",
        "    w_0=w_0-alpha*grad_w_0\n",
        "    if abs(grad_w_0) < 0.001:\n",
        "      break\n",
        "  return W,w_0\n",
        "models = np.zeros(1)\n",
        "w0 = 0\n",
        "def predict_linear_rgr(x,th):\n",
        "  if x@model + w0 < th:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "    \n",
        "def eval12(data_tt,th,order):\n",
        "  n = 0\n",
        "  tp = 0\n",
        "  tn = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  right = 0\n",
        "  tot = 0\n",
        "  for i in data_tt.items():\n",
        "    ss = kernel(i[1],order)\n",
        "    for j in ss:\n",
        "      tot+=1\n",
        "      temp = int(predict_linear_rgr(j,th))\n",
        "      if temp==i[0]:\n",
        "        right+=1\n",
        "      if temp==1 and i[0]==1:\n",
        "        tp+=1\n",
        "      elif temp==0 and i[0]==0:\n",
        "        tn+=1\n",
        "      elif temp!=0 and i[0]==0:\n",
        "        fn+=1\n",
        "      else:\n",
        "        fp+=1\n",
        "  n = tot\n",
        "  prescion = tp/(tp+fp)\n",
        "  recall = tp/(tp+fn)\n",
        "  f1 = 2/(1/recall+1/prescion)\n",
        "  accuracy = right/n\n",
        "  tpr = 1\n",
        "  if tp + fn != 0:\n",
        "    tpr = tp/(tp+fn)\n",
        "  fpr = 1\n",
        "  if fp + tn != 0:\n",
        "    fpr = fp/(fp+tn)\n",
        "  return accuracy,prescion,f1,recall,tpr,fpr,tp,tn,fn,fp\n",
        "\n",
        "# caller\n",
        "model,w0 =  linear_regr_reg_MAE_elasNet_vectorized(kernel(X,2),y,0.01,0,0)\n",
        "print(eval12(data_tt,0.5,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvqDiShxJXLM",
        "outputId": "767c0fd5-7874-4b41-e72f-40691c545da5"
      },
      "outputs": [],
      "source": [
        "# Linear Regression with MSE elastic Net\n",
        "# Trains and outputs models \n",
        "def linear_regr_MSE_elasnet_vec(X,y,alpha,lambda1,lambda2,max_iter=100000):\n",
        "    m,n=X.shape\n",
        "    W=np.array( np.random.uniform(low=0.001,high=1, size=(X[0].shape[0],1)) )\n",
        "    w_0=0\n",
        "    y = np.reshape(y,(y.shape[0],1))\n",
        "    # print(y.shape)\n",
        "    for i in range(max_iter):\n",
        "        Y_pr=X.dot(W)+w_0\n",
        "        WW=np.where(W>0,lambda1,-lambda1)\n",
        "        grad_W=(-2*X.T@(y-Y_pr) +WW+2*lambda2*W)/m\n",
        "        grad_w_0=-2*np.sum(y-Y_pr)/m\n",
        "        W=W-alpha*grad_W\n",
        "        w_0-=alpha*grad_w_0\n",
        "        if(abs(grad_w_0)<1e-7):\n",
        "          break\n",
        "    return (W,w_0)\n",
        "\n",
        "# predicts output for a particalar Sample witha a given THreshold\n",
        "def predict_loge1t(x,th):\n",
        "  if x@model + w_0 < th:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "    \n",
        "# Evaluvates all testset and returns relevent results\n",
        "def eval2(data_tt,th,order):\n",
        "  n = 0\n",
        "  tp = 0\n",
        "  tn = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  right = 0\n",
        "  tot = 0\n",
        "  for i in data_tt.items():\n",
        "    ss = kernel(i[1],order)\n",
        "    for j in ss:\n",
        "      tot+=1\n",
        "      temp = int(predict_loge1t(j,th))\n",
        "      if temp==i[0]:\n",
        "        right+=1\n",
        "      if temp==1 and i[0]==1:\n",
        "        tp+=1\n",
        "      elif temp==0 and i[0]==0:\n",
        "        tn+=1\n",
        "      elif temp!=0 and i[0]==0:\n",
        "        fn+=1\n",
        "      else:\n",
        "        fp+=1\n",
        "  n = tot\n",
        "  prescion = tp/(tp+fp)\n",
        "  recall = tp/(tp+fn)\n",
        "  f1 = 2/(1/recall+1/prescion)\n",
        "  accuracy = right/n\n",
        "  tpr = 1\n",
        "  if tp + fn != 0:\n",
        "    tpr = tp/(tp+fn)\n",
        "  fpr = 1\n",
        "  if fp + tn != 0:\n",
        "    fpr = fp/(fp+tn)\n",
        "  return accuracy,prescion,f1,recall,tpr,fpr,tp,tn,fn,fp\n",
        "model,w_0 =  linear_regr_MSE_elasnet_vec(kernel(X,2),y,0.1,0,0)\n",
        "print(eval2(data_tt,0.5,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# logestic regression with all regularizer cross entropy\n",
        "\n",
        "# some data preproceesing (adding 1 toa acount for w0)\n",
        "def data_magic(X):\n",
        "  nupea = []\n",
        "  for i in range(len(X)):\n",
        "    nupea.append( np.append(X[i],[1]) )\n",
        "  return np.array(nupea)\n",
        "  \n",
        "# trains a logetistic regression for one label (one vs all used)\n",
        "def magic(X,y,alpha,max_iter,lambda1,lambda2):\n",
        "  X = data_magic(X)\n",
        "  m=X.shape[0]\n",
        "  n=X.shape[1]\n",
        "\n",
        "  w=np.random.rand(X.shape[1])\n",
        "  \n",
        "  for i in range(max_iter):\n",
        "    grad=X.T@(sigmoid(X@w)-y)/m\n",
        "    for j in range(n-1):\n",
        "      if w[j]>0:\n",
        "        grad[j]+=(lambda1+2*lambda2*w[j])/m\n",
        "      else:\n",
        "        grad[j]+=(-lambda1+2*lambda2*w[j])/m\n",
        "    w=w-alpha*grad \n",
        "  return w\n",
        "\n",
        "# predicts label for a new input\n",
        "def predict_loget(x,th):\n",
        "  if sigmoid(np.append(x,1)@model) < th:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "#evaluates entire train set and returns relevant results for logisitic regression\n",
        "def eval1(data_tt,th,order):\n",
        "  n = 0\n",
        "  tp = 0\n",
        "  tn = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  right = 0\n",
        "  tot = 0\n",
        "  for i in data_tt.items():\n",
        "    ss = kernel(i[1],order)\n",
        "    for j in ss:\n",
        "      tot+=1\n",
        "      temp = int(predict_loget(j,th))\n",
        "      if temp==i[0]:\n",
        "        right+=1\n",
        "      if temp==1 and i[0]==1:\n",
        "        tp+=1\n",
        "      elif temp==0 and i[0]==0:\n",
        "        tn+=1\n",
        "      elif temp!=0 and i[0]==0:\n",
        "        fn+=1\n",
        "      else:\n",
        "        fp+=1\n",
        "  n = tot\n",
        "  prescion = tp/(tp+fp)\n",
        "  recall = tp/(tp+fn)\n",
        "  f1 = 2/(1/recall+1/prescion)\n",
        "  accuracy = right/n\n",
        "  tpr = 1\n",
        "  if tp + fn != 0:\n",
        "    tpr = tp/(tp+fn)\n",
        "  fpr = 1\n",
        "  if fp + tn != 0:\n",
        "    fpr = fp/(fp+tn)\n",
        "  return accuracy,prescion,f1,recall,tpr,fpr,tp,tn,fn,fp\n",
        "model =  magic(kernel(X,2),y,0.1,30000,0,0)\n",
        "print(eval1(data_tt,0.5,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# code for ROC and bais varaince and other things (Helper Functions)\n",
        "results = []\n",
        "roc = []\n",
        "for i in range(1,40):\n",
        "  results.append((knn_caller(data_trr,data_ttt,40,(2**i)/1e10)))\n",
        "roc = []\n",
        "test_loss = []\n",
        "train_loss = []\n",
        "for i in range(0,10):\n",
        "    gmmtrain(1)\n",
        "    oo = check_gmm(1,(10**i)/1e2)\n",
        "    print(oo)\n",
        "    roc.append([oo[4],oo[5]])\n",
        "    test_loss.append(oo[0])\n",
        "    train_loss.append(oo[6])\n",
        "roc = []\n",
        "for i in results:\n",
        "    roc.append((i[4],i[5]))\n",
        "roc = np.array(roc)\n",
        "plt.plot(roc.T[1],roc.T[0])\n",
        "plt.xlim(-0.01,1)\n",
        "plt.ylim(0,1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Q1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

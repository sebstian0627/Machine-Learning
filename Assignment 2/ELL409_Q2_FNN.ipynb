{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELL409_Q2_FNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7hqJNyoopdA"
      },
      "source": [
        "import numpy as np\r\n",
        "#import math\r\n",
        "\r\n",
        "import torch\r\n",
        "\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS8cvESnKirC"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZv0kzvS6uFF"
      },
      "source": [
        "# -------preprocessing of data ---------\r\n",
        "# x1 = list(range(len(traindata)))\r\n",
        "# np.random.shuffle(x1)\r\n",
        "# x2 = list(range(len(testdata)))\r\n",
        "# np.random.shuffle(x2)\r\n",
        "\r\n",
        "# traindata1 = traindata[np.argsort(x1)]\r\n",
        "# trainlabels1 = trainlabels[np.argsort(x1)]\r\n",
        "# testdata1 = testdata[np.argsort(x2)]\r\n",
        "# testlabels1 = testabels[np.argsort(x2)]\r\n",
        "\r\n",
        "# gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\r\n",
        "# #np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\r\n",
        "# # from PIL import Image\r\n",
        "\r\n",
        "# # # for td in traindata:\r\n",
        "# # td = traindata[10]\r\n",
        "# # print(td.T.shape)\r\n",
        "# # im = Image.fromarray(td.T)\r\n",
        "# # im.save('out.jpg')\r\n",
        "# # #im.convert('RGB').save('out.jpg')\r\n",
        "# #   #im.show()\r\n",
        "  \r\n",
        "# # td = np.dot(td.T,[0.2125, 0.7154, 0.0721])\r\n",
        "# #   # print(td[0])\r\n",
        "# # img = Image.fromarray(td)\r\n",
        "\r\n",
        "# # img.convert('RGB').save('out.png')\r\n",
        "\r\n",
        "# greydata = []\r\n",
        "# #i = 0\r\n",
        "# for td in testdata1:\r\n",
        "#     #print(td.shape)\r\n",
        "#     greydata.append(np.dot(td.T,[0.2125, 0.7154, 0.0721]).flatten())\r\n",
        "\r\n",
        "# greydata = np.asarray(greydata)\r\n",
        "\r\n",
        "# np.save(datapath+\"grey_testdata.npy\",greydata)\r\n",
        "# np.save(datapath+\"grey_testlabel.npy\",testlabels1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN31yhpmZ6u0"
      },
      "source": [
        "# # BATCH_SIZE = 4\r\n",
        "\r\n",
        "# # transform = transforms.ToTensor()\r\n",
        "\r\n",
        "# # traindata = torchvision.datasets.MNIST('/tmp', train=True, download=True, transform=transform)\r\n",
        "# # trainloader = torch.utils.data.DataLoader(traindata, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\r\n",
        "\r\n",
        "# # testdata = torchvision.datasets.MNIST('/tmp', train=False, download=True, transform=transform)\r\n",
        "# # testloader = torch.utils.data.DataLoader(testdata, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\r\n",
        "# dataiter = iter(testloader)\r\n",
        "\r\n",
        "# transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0,0,0), (1,1,1))]) #change normalize values if need be\r\n",
        "\r\n",
        "# # svhn = torchvision.datasets.SVHN('/tmp', download=True, transform=transform)\r\n",
        "# mnist = torchvision.datasets.MNIST('/tmp', download=True, transform=transform)\r\n",
        "\r\n",
        "# # svhn_loader = torch.utils.data.DataLoader(dataset=svhn,\r\n",
        "# #                                           batch_size=1,\r\n",
        "# #                                           shuffle=True,\r\n",
        "# #                                           num_workers=2)\r\n",
        "\r\n",
        "# mnist_loader = torch.utils.data.DataLoader(dataset=mnist,\r\n",
        "#                                             batch_size=4,\r\n",
        "#                                             shuffle=True,\r\n",
        "#                                             num_workers=2)\r\n",
        "# dataiter = iter(mnist_loader)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3xRH0nVObC_"
      },
      "source": [
        "datapath = \"/content/drive/MyDrive/A2_data/\" #already shuffled n flattened data\r\n",
        "traindata = np.load(datapath + \"grey_traindata.npy\", mmap_mode='r')\r\n",
        "trainlabels = np.load(datapath + \"grey_trainlabel.npy\", mmap_mode='r')\r\n",
        "testdata = np.load(datapath + \"grey_testdata.npy\", mmap_mode='r')\r\n",
        "testabels = np.load(datapath + \"grey_testlabel.npy\", mmap_mode='r')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt2AfQhhGrBj"
      },
      "source": [
        "indxs = np.random.choice(len(traindata),int(len(traindata)/4))\r\n",
        "traindata = traindata[indxs]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOGCQN4AJLe6"
      },
      "source": [
        "indxs = np.random.choice(len(testdata),int(len(testdata)/4))\r\n",
        "testdata = testdata[indxs]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcnZk5of6RsD"
      },
      "source": [
        "if want MNIST, begin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy6_lOklZrvf"
      },
      "source": [
        "data = np.genfromtxt(\"/content/sample_data/mnist_train_small.csv\", skip_header=True,delimiter=\",\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liScLeb1bCEw"
      },
      "source": [
        "traindata = []\r\n",
        "trainlabels = []\r\n",
        "\r\n",
        "i = 0\r\n",
        "for val in data:\r\n",
        "  if(i<10000):\r\n",
        "    traindata.append(val[1:])\r\n",
        "    trainlabels.append(val[0])\r\n",
        "  i+=1"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LODdyytFbR0l"
      },
      "source": [
        "data = np.genfromtxt(\"/content/sample_data/mnist_test.csv\", skip_header=True,delimiter=\",\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPFw-2BTtc3p",
        "outputId": "27dbb1ac-dd63-4b04-8734-6120b514e46a"
      },
      "source": [
        "print(len(data))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBTmqoBPbWiP"
      },
      "source": [
        "testdata = []\r\n",
        "testlabels = []\r\n",
        "i = 0\r\n",
        "for val in data:\r\n",
        "  if(i<5000):\r\n",
        "    testdata.append(val[1:])\r\n",
        "    testlabels.append(val[0])\r\n",
        "  i+=1"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSOpHG226UKc"
      },
      "source": [
        "mnist, end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sys8Kk9a83hA"
      },
      "source": [
        "mu = np.mean(traindata,axis=0)\r\n",
        "std = np.std(traindata,axis=0)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa_NAlmu7qhy"
      },
      "source": [
        "traindata1 = (traindata - mu)/(std+10**-5) \r\n",
        "testdata1 = (testdata - mu)/(std+10**-5) "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7APHV7-SHaA3"
      },
      "source": [
        "ncls = 10\r\n",
        "trainlabels1 = []\r\n",
        "for label in trainlabels:\r\n",
        "  v = np.zeros(shape=(ncls,))\r\n",
        "  #print(label)\r\n",
        "  v[int(label)] = 1\r\n",
        "  trainlabels1.append(v)\r\n",
        "  #print(v)\r\n",
        "\r\n",
        "#  break\r\n",
        "# trainlabels = np.asarray(trainlabels1)\r\n",
        "# del trainlabels1\r\n",
        "# print(trainlabels.shape)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7N2uz3RH375"
      },
      "source": [
        "testlabels1 = []\r\n",
        "for label in testlabels:\r\n",
        "  v = np.zeros(shape=(ncls,))\r\n",
        "  v[int(label)] = 1\r\n",
        "  testlabels1.append(v)\r\n",
        "\r\n",
        "# testabels = np.asarray(testlabels1)\r\n",
        "# del testlabels1\r\n",
        "# print(testabels.shape)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEYuW7QLNum8"
      },
      "source": [
        "univ_seed = 42\r\n",
        "np.random.seed(univ_seed)\r\n",
        "#reproducibility"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXEMkCqHKaMA"
      },
      "source": [
        "class layer:\r\n",
        "  #layer object - each is a FC layer \r\n",
        "\r\n",
        "  def __init__(self,num_in,num_out,weights=None,b=None,activation=None):\r\n",
        "    \r\n",
        "    self.shapeval = (num_in,num_out)\r\n",
        "    self.activation = activation\r\n",
        "    self.wts = np.random.randn(num_in,num_out) if weights is None else weights\r\n",
        "    self.bias = np.random.randn(num_out) if b is None else b\r\n",
        "    self.err = 0\r\n",
        "    self.diffval = 0\r\n",
        "    self.penalty_norm = None\r\n",
        "    self.activation_memo = None\r\n",
        "\r\n",
        "  def apply_activation(self,val,some_other=None):\r\n",
        "    if self.activation is None:\r\n",
        "      return val\r\n",
        "\r\n",
        "    #add activations inside class for speed\r\n",
        "    if self.activation == \"sigmoid\":\r\n",
        "      return 1/(1.0+np.exp(-val))\r\n",
        "    \r\n",
        "    if self.activation == \"softmax\":\r\n",
        "      e = np.exp(val)\r\n",
        "      return e / np.sum(e)\r\n",
        "\r\n",
        "    if self.activation == \"tanh\":\r\n",
        "      return np.tanh(val)\r\n",
        "\r\n",
        "    if self.activation == \"relu\":\r\n",
        "      return np.maximum(val, 0)\r\n",
        "\r\n",
        "    else: #undefined activation\r\n",
        "      if some_other is not None:\r\n",
        "        #of the form activation(input)\r\n",
        "        return some_other(val)\r\n",
        "\r\n",
        "    return val \r\n",
        "\r\n",
        "  def activation_derivative(self,val,some_other=None):\r\n",
        "    if self.activation == None:\r\n",
        "      return val\r\n",
        "    \r\n",
        "    if self.activation == \"sigmoid\":\r\n",
        "      tmp = 1/(1.0+np.exp(-val))\r\n",
        "      return tmp*(1-tmp)\r\n",
        "    \r\n",
        "    if self.activation == \"tanh\":\r\n",
        "      v = np.tanh(val)\r\n",
        "      return 1 - val**2\r\n",
        "    \r\n",
        "    if self.activation == \"softmax\":\r\n",
        "      e = np.exp(val)\r\n",
        "      softmax = e / np.sum(e)\r\n",
        "      s = softmax.reshape(1,-1)      \r\n",
        "      return np.diagflat(s) - np.dot(s, s.T)\r\n",
        "    \r\n",
        "    if self.activation == \"relu\":\r\n",
        "      return 1. * (val > 0)\r\n",
        "\r\n",
        "    else: #undefined activation\r\n",
        "      if some_other is not None:\r\n",
        "        #of the form activation_derivative(input)\r\n",
        "        return some_other(val)\r\n",
        "      \r\n",
        "    return val\r\n",
        "\r\n",
        "  def after_apply_activ(self,val):\r\n",
        "    \r\n",
        "    net_out = np.dot(val,self.wts) + self.bias\r\n",
        "    self.activation_memo = self.apply_activation(net_out)\r\n",
        "    return self.activation_memo\r\n",
        "  "
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rut7YVIlzPjN"
      },
      "source": [
        "class FNN:\r\n",
        "  #FNN object - describes a FNN/MLP\r\n",
        "  def __init__(self):\r\n",
        " \r\n",
        "    self.network = list()\r\n",
        "    #---better to make a diff layer class-----\r\n",
        "    # self.network.append(np.random.random(size=(num_feat,num_hide[0])))\r\n",
        "    # self.network_bias.append(np.ones(size=(num_hide[0],1)))\r\n",
        "\r\n",
        "    # for i in range(0,len(num_hide)-1):\r\n",
        "    #   self.network.append(np.random.random(size=(num_hide[i],num_hide[i+1])))\r\n",
        "    #   self.network_bias.append(np.ones(size=(num_hide[i+1],1)))\r\n",
        "    \r\n",
        "    # self.network.append(np.random.random(size=(num_hide[-1],num_out)))\r\n",
        "    # self.network_bias.append(np.ones(size=(num_out,1)))\r\n",
        "    # \r\n",
        "    # self.activations = []\r\n",
        "\r\n",
        "  def build_fnn(self,num_feat,num_hide,num_out,activns):\r\n",
        "#     assert len(num_hide)+1 == len(activns)\r\n",
        "     self.network = list()\r\n",
        "\r\n",
        "     lay_in = layer(num_feat,num_hide[0],activation=activns[0])\r\n",
        "     self.network.append(lay_in)\r\n",
        "     \r\n",
        "     for j in range(0,len(num_hide)-1):\r\n",
        "       self.network.append(layer(num_hide[j],num_hide[j+1],activation=activns[j+1]))\r\n",
        "       #pass\r\n",
        "\r\n",
        "     self.network.append(layer(num_hide[-1],num_out,activation=activns[-1]))\r\n",
        "     return 0\r\n",
        "\r\n",
        "  def add_layer(self,num_in,num_out,activn,is_out=False):\r\n",
        "    if(is_out): #if it is supposed to be new output layer\r\n",
        "      v = self.network[-1].shapeval[1]\r\n",
        "      assert v==num_in\r\n",
        "      self.network.append(layer(num_in,num_out,activation=activn))\r\n",
        "    \r\n",
        "    else: #num in and num out are just useless\r\n",
        "      vin = self.network[-2].shapeval[1]\r\n",
        "      vout = self.network[-1].shapeval[0]\r\n",
        "      self.network.append(layer(vin,vout,activation=activn))\r\n",
        "      v11 = self.network[-2]\r\n",
        "      self.network[-2] = self.network[-1]\r\n",
        "      self.network[-1] = v11\r\n",
        "\r\n",
        "  def loss(self,x,truev,loss_fn=\"mse\"):\r\n",
        "\r\n",
        "    if(loss_fn==\"mse\"):\r\n",
        "        return 0.5*np.mean(np.square(x-truev))\r\n",
        "    return 0\r\n",
        "  \r\n",
        "  def loss_der(self,x,truev,loss_fn=\"mse\"):\r\n",
        "    if(loss_fn==\"mse\"):\r\n",
        "      return np.mean((x-truev))\r\n",
        "    return 0\r\n",
        "    #pass\r\n",
        "\r\n",
        "  def fwd_pass(self,inp):\r\n",
        "    for lay in self.network:\r\n",
        "      inp = lay.after_apply_activ(inp)\r\n",
        "    return inp\r\n",
        "\r\n",
        "  def dropout(self,X, drop_probability):\r\n",
        "      keep_probability = 1 - drop_probability\r\n",
        "      mask = np.random.uniform(0, 1.0, X.shape) < keep_probability\r\n",
        "      scale = 0.0\r\n",
        "      if keep_probability > 0.0:\r\n",
        "          scale = (1/keep_probability)\r\n",
        "\r\n",
        "      return mask * X * scale\r\n",
        "\r\n",
        "  def backprop(self,inp,truev,eta,regularizer,loss_fn):\r\n",
        "    outp = self.fwd_pass(inp)\r\n",
        "\r\n",
        "    #backward pass: find diffvals\r\n",
        "    for i in range(len(self.network)):\r\n",
        "      lay_inx = len(self.network)-i-1\r\n",
        "      layr = self.network[lay_inx]\r\n",
        "\r\n",
        "      if(i==0): #implies last/op layer\r\n",
        "        layr.err = self.loss_der(outp,truev,loss_fn)\r\n",
        "        layr.diffval = (layr.err)*layr.activation_derivative(layr.activation_memo)\r\n",
        "\r\n",
        "      else:\r\n",
        "        layr_back = self.network[lay_inx+1]\r\n",
        "        layr.err = np.dot(layr_back.wts,layr_back.diffval)\r\n",
        "        layr.diffval = layr.err*layr.activation_derivative(layr.activation_memo)        \r\n",
        "      \r\n",
        "      self.network[lay_inx] = layr\r\n",
        "      \r\n",
        "      if regularizer is not None:\r\n",
        "        if(regularizer==\"L1\"):\r\n",
        "   #       print(layr.wts.shape)\r\n",
        "          lamd_v = 0.5\r\n",
        "          tempv = np.ones(shape=layr.wts.shape)\r\n",
        "          for val in range(layr.wts.shape[0]):\r\n",
        "            for v1 in range(len(layr.wts[val])):\r\n",
        "              if(layr.wts[val][v1]<0):\r\n",
        "                tempv[val][v1] = -1\r\n",
        "              if(layr.wts[val][v1]==0):\r\n",
        "                tempv[val][v1] = 0\r\n",
        "              \r\n",
        "          layr.penalty_norm = lamd_v*np.sum(tempv,axis=0)\r\n",
        "          del(tempv)\r\n",
        "\r\n",
        "        if(regularizer==\"L2\"):\r\n",
        "          lamd_v = 0.5\r\n",
        "        #  print(layr.wts.shape)\r\n",
        "          layr.penalty_norm = lamd_v*np.sum(layr.wts,axis=0)\r\n",
        "       #   print(layr.penalty_norm.shape)\r\n",
        "\r\n",
        "        if(regularizer==\"dropout\"):\r\n",
        "          for lr in self.network:\r\n",
        "            lr.wts = self.dropout(lr.wts,0.2)\r\n",
        "          layr.penalty_norm = None\r\n",
        "      \r\n",
        "      if layr.penalty_norm is not None:\r\n",
        "      #    print(layr.diffval.shape)\r\n",
        "      #    print(layr.penalty_norm.shape)\r\n",
        "          layr.diffval += layr.penalty_norm\r\n",
        "      \r\n",
        "      self.network[lay_inx] = layr\r\n",
        "\r\n",
        "    #fwd pass: weight update\r\n",
        "    for i in range(len(self.network)):\r\n",
        "      if(i!=0):\r\n",
        "        mtrx = np.atleast_2d(self.network[i-1].activation_memo)\r\n",
        "      else:\r\n",
        "        mtrx = np.atleast_2d(inp)\r\n",
        "\r\n",
        "      self.network[i].wts -= self.network[i].diffval*mtrx.T*eta\r\n",
        "\r\n",
        "  def predict(self,inpt,truev):\r\n",
        "    outp = self.fwd_pass(inpt)\r\n",
        "    if np.argmax(outp) == np.argmax(truev):\r\n",
        "      return True\r\n",
        "    #else:\r\n",
        "    return False\r\n",
        "\r\n",
        "  def find_acc(self,outp,truev):\r\n",
        "    all_v = 0\r\n",
        "    truevs = 0\r\n",
        "\r\n",
        "    for inx1 in range(len(outp)):\r\n",
        "      outpv = outp[inx1]\r\n",
        "      #print(outpv)\r\n",
        "      #print(truev)\r\n",
        "\r\n",
        "      truevv = truev[inx1]\r\n",
        "      \r\n",
        "      bn = self.predict(outpv,truevv)\r\n",
        "      if(bn):\r\n",
        "        truevs+=1\r\n",
        "      all_v +=1\r\n",
        "    print(truevs)\r\n",
        "    print(all_v)\r\n",
        "    return round(float(truevs/all_v),3)    \r\n",
        "\r\n",
        "  def train_fnn(self,testin,testtrue,inpt,truev,eta,maxiter,batch_size=32,regularizer=None,loss_fn=\"mse\"):\r\n",
        "    errs = []\r\n",
        "    tracc = []\r\n",
        "    testacc = []\r\n",
        "\r\n",
        "    if(batch_size!=0):\r\n",
        "      num_bins = int(len(inpt)/batch_size)\r\n",
        "    else:\r\n",
        "      num_bins = 1\r\n",
        "    eps = 10**-5\r\n",
        "    \r\n",
        "    for iter in range(maxiter):\r\n",
        "      err1tmp = []  \r\n",
        "      minb_inx = np.random.randint(0,num_bins)\r\n",
        "\r\n",
        "      if(batch_size!=0):\r\n",
        "        inxsl = minb_inx*batch_size\r\n",
        "        inpt1 = inpt[inxsl:] if minb_inx==num_bins-1 else inpt[inxsl:inxsl+batch_size]\r\n",
        "        truev1 = truev[inxsl:] if minb_inx==num_bins-1 else truev[inxsl:inxsl+batch_size]\r\n",
        "      else:\r\n",
        "        inpt1 = inpt\r\n",
        "        truev1 = truev\r\n",
        "\r\n",
        "      if(regularizer==\"batch\"):\r\n",
        "        mu1 = np.mean(inpt1)\r\n",
        "        sd1 = np.std(inpt1)\r\n",
        "        inpt1 = (inpt1-mu)/(sd1 + eps)\r\n",
        "      \r\n",
        "      for j in range(len(inpt1)):\r\n",
        "        self.backprop(inpt1[j],truev1[j],eta,regularizer,loss_fn)\r\n",
        "        err1tmp.append(self.loss(self.fwd_pass(inpt1[j]),truev1[j],loss_fn))\r\n",
        "\r\n",
        "        \r\n",
        "      errs.append(np.mean(np.asarray(err1tmp)))\r\n",
        "      print(err1tmp)\r\n",
        "      print(\"Epoch: %s, Loss: %f\" % (iter,errs[-1]))  \r\n",
        "      \r\n",
        "      if(iter%5==0):\r\n",
        "        tracc.append(self.find_acc(inpt,truev))\r\n",
        "        testacc.append(self.find_acc(testin,testtrue))\r\n",
        "\r\n",
        "    # checkpoints// commented\r\n",
        "    # with open(datapath+\"vals.pkl\",'wb') as pf:\r\n",
        "    #     pickle.dump(nn.network,pf,pickle.HIGHEST_PROTOCOL) wt saving so code can be resumed incase of BT\r\n",
        "\r\n",
        "    print(\"accuracy: %f\" %(self.find_acc(inpt,truev)))\r\n",
        "    \r\n",
        "    return errs,tracc,testacc\r\n",
        "  \r\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpNqea5_Yg7G"
      },
      "source": [
        "# from sklearn.decomposition import PCA\r\n",
        "# pca = PCA(n_components=10, svd_solver='full')\r\n",
        "# pca.fit(traindata1.T)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENubMxxqzbCp"
      },
      "source": [
        "nn = FNN()\r\n",
        "# nn.build_fnn(len(traindata1[0]),[800,500,250],ncls,[\"tanh\",\"sigmoid\",\"sigmoid\",\"tanh\",\"sigmoid\",\"sigmoid\"]) --> MNIST\r\n",
        "# nn.build_fnn(pca.components_,[10,10],ncls,[\"tanh\",\"sigmoid\",\"sigmoid\",\"tanh\",\"sigmoid\",\"sigmoid\"]) --> with pca if want to experiment\r\n",
        "nn.build_fnn(len(traindata1[0]),[800,500,100,50],ncls,[\"tanh\",\"sigmoid\",\"sigmoid\",\"sigmoid\",\"sigmoid\",\"sigmoid\"]) #build and init weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLM_KMEizzNI"
      },
      "source": [
        "errs,tr,ts = nn.train_fnn(testdata1,testlabels1,traindata1,trainlabels1,10**-3,100,batch_size=0,regularizer=\"L2\") #0 batch size means no minibatches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNEVsCE4tmFG"
      },
      "source": [
        "# print(errs)\r\n",
        "# print(tr)\r\n",
        "# print(ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wXfCY6htyys"
      },
      "source": [
        "# ----code for visualization - keep modifyig while generating plots\r\n",
        "# import matplotlib.pyplot as plt\r\n",
        "# plt.plot(range(epoch),errs,label=\"train\")\r\n",
        "# # plt.plot(range(0,100,10),ts,label=\"test\")\r\n",
        "# plt.xlabel(\"Epoch\")\r\n",
        "# plt.ylabel(\"Loss\")\r\n",
        "# plt.title(\"FNN, MSE loss, lr 10^-6\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELL409_alexnet_vgg16_Q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjdbZNNZkELI"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "import torch.utils as utils\r\n",
        "\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as datasets\r\n",
        "\r\n",
        "from sklearn import decomposition\r\n",
        "from sklearn import manifold\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import math\r\n",
        "import copy\r\n",
        "import random\r\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWH6QN9zkKa6",
        "outputId": "4b824d11-cdd2-45dc-9a05-55cf70b06742"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlCnqqI2kV_5"
      },
      "source": [
        "univseed = 42\r\n",
        "\r\n",
        "random.seed(univseed)\r\n",
        "np.random.seed(univseed)\r\n",
        "torch.manual_seed(univseed)\r\n",
        "torch.cuda.manual_seed(univseed)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOL4bhm94vTC"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3Cg9pkIkefO"
      },
      "source": [
        "class alexnet(nn.Module):\r\n",
        "  def __init__(self, output_dim):\r\n",
        "    super().__init__()\r\n",
        "      \r\n",
        "    self.features = nn.Sequential(\r\n",
        "      nn.Conv2d(1, 3, (1, 1),stride=1), # uncomment to run mnist\r\n",
        "      nn.Conv2d(in_channels=3,out_channels=96,kernel_size=11,stride=4,padding=2,bias=False),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2,padding=0),\r\n",
        "      nn.Conv2d(in_channels=96,out_channels=192,kernel_size=5,stride=1,padding=2,bias=False),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2,padding=0),\r\n",
        "      nn.Conv2d(in_channels=192,out_channels=384,kernel_size=3,stride=1,padding=1,bias=False),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3,stride=1,padding=1,bias=False),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1,bias=False),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2, padding=0),    \r\n",
        "    )\r\n",
        "    \r\n",
        "    self.classifier = nn.Sequential(\r\n",
        "      nn.Dropout(0.5),\r\n",
        "      nn.Linear(256 * 6 * 6, 4096),\r\n",
        "      nn.ReLU(inplace = True),\r\n",
        "      nn.Dropout(0.5),\r\n",
        "      nn.Linear(4096, 4096),\r\n",
        "      nn.ReLU(inplace = True),\r\n",
        "      nn.Linear(4096, output_dim),\r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.features(x)\r\n",
        "    h = x.view(x.shape[0], -1)\r\n",
        "    x = self.classifier(h)\r\n",
        "    return x\r\n",
        "\r\n",
        "model_alex = alexnet(10)\r\n",
        "print('Using device:', device)\r\n",
        "model_alex.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TApYkewkwiG"
      },
      "source": [
        "class VGG16(nn.Module):\r\n",
        "  def __init__(self, n_classes=10):\r\n",
        "    super(VGG16, self).__init__()\r\n",
        "    self.layer1 = nn.Sequential(\r\n",
        "      nn.Conv2d(1, 3, (1, 1),stride=1), #uncomment for mnist\r\n",
        "      nn.Conv2d(3, 64, kernel_size=3, padding=1),\r\n",
        "      #nn.Conv2d(1, 64, kernel_size=3, padding=1), #this can also be used instead of top 2 lines\r\n",
        "      nn.BatchNorm2d(64),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Conv2d(64, 64, kernel_size=3, padding=1),\r\n",
        "      nn.BatchNorm2d(64),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
        "\r\n",
        "    self.layer2 = nn.Sequential(\r\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\r\n",
        "      nn.BatchNorm2d(128),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Conv2d(128, 128, kernel_size=3, padding=1),\r\n",
        "      nn.BatchNorm2d(128),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
        "\r\n",
        "    self.layer3 = nn.Sequential(\r\n",
        "      nn.Conv2d(128, 256, kernel_size=3, padding=1),\r\n",
        "      nn.BatchNorm2d(256),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Conv2d(256, 256, kernel_size=3, padding=1),\r\n",
        "      nn.BatchNorm2d(256),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Conv2d(256, 256, kernel_size=1, padding=0),\r\n",
        "      nn.BatchNorm2d(256),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
        "\r\n",
        "    self.layer4 = nn.Sequential(\r\n",
        "      nn.Conv2d(256, 512, kernel_size=3, padding=1),\r\n",
        "      nn.BatchNorm2d(512),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Conv2d(512, 512, kernel_size=3, padding=1),\r\n",
        "      nn.BatchNorm2d(512),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Conv2d(512, 512, kernel_size=1, padding=0),\r\n",
        "      nn.BatchNorm2d(512),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
        "\r\n",
        "    self.layer5 = nn.Sequential(\r\n",
        "      nn.Conv2d(512, 512, kernel_size=3, padding=1),\r\n",
        "      nn.BatchNorm2d(512),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Conv2d(512, 512, kernel_size=3, padding=1),\r\n",
        "      nn.BatchNorm2d(512),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Conv2d(512, 512, kernel_size=1, padding=0),\r\n",
        "      nn.BatchNorm2d(512),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2))\r\n",
        "    \r\n",
        "    self.classifier = nn.Sequential(\r\n",
        "      nn.Linear(in_features=512*7*7,out_features=4096),\r\n",
        "      nn.Dropout(p=0.2),\r\n",
        "      nn.Linear(in_features=4096, out_features=4096),\r\n",
        "      nn.Dropout(p=0.2),\r\n",
        "      nn.Linear(in_features=4096, out_features=n_classes)\r\n",
        "        )   \r\n",
        "         \r\n",
        "    def forward(self, x):\r\n",
        "      out = self.layer1(x)\r\n",
        "      out = self.layer2(out)\r\n",
        "      out = self.layer3(out)\r\n",
        "      out = self.layer4(out)\r\n",
        "      out = self.layer5(out)\r\n",
        "      out = out.view(out.size(0), -1)\r\n",
        "      out = self.classifier(out)\r\n",
        "      #print(out)\r\n",
        "      return out\r\n",
        "\r\n",
        "model_vgg = VGG16(10)\r\n",
        "model_vgg.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bulwl1Ldctp-"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='sum')\r\n",
        "optimizer = optim.Adam(model_alex.parameters(), lr=1e-3, betas=(0.9, 0.99))\r\n",
        "# lrt = 0.001; momt = 0;\r\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lrt,momentum=momt)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9I3Fi-ddCzT"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((227,227)),transforms.Normalize([122.5],[255])]) #make 224, 224 for vgg\r\n",
        "\r\n",
        "mnist = datasets.MNIST('/tmp', download=True, transform=transform)\r\n",
        "mnist_loader = torch.utils.data.DataLoader(dataset=mnist,\r\n",
        "                                            batch_size=32,\r\n",
        "                                            shuffle=True,\r\n",
        "                                            num_workers=4)\r\n",
        "\r\n",
        "mnist_test = datasets.MNIST('/tmp',train=False,transform=transform)\r\n",
        "mnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\r\n",
        "                                            batch_size=32,\r\n",
        "                                            shuffle=True,\r\n",
        "                                            num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR5ovuFSdmvu"
      },
      "source": [
        "# totdata = datasets.ImageFolder(root='/content/drive/MyDrive/tinyImagenet_dataset',transform=transform)\r\n",
        "# testdata, traindata = utils.data.random_split(totdata,[int(0.15*len(totdata)),len(totdata)-int(0.15*len(totdata))])\r\n",
        "# data_loader = utils.data.DataLoader(traindata,batch_size=4, shuffle=True)\r\n",
        "# test_loader = utils.data.DataLoader(testdata,batch_size=4, shuffle=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO3OdJHUX_ts"
      },
      "source": [
        "def findacc(testloader,net):\r\n",
        "  correct = 0\r\n",
        "  total = 0\r\n",
        "  with torch.no_grad():\r\n",
        "    for data in testloader:\r\n",
        "      images, labels = data\r\n",
        "      outputs = net(images)\r\n",
        "      _, predicted = torch.max(outputs.data, 1)\r\n",
        "      total += labels.size(0)\r\n",
        "      correct += (predicted == labels).sum().item()\r\n",
        "      # if(total>50):\r\n",
        "      #   break  \r\n",
        "  return float(correct/total)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFkkqLElnj5o"
      },
      "source": [
        "epoch = 10\r\n",
        "trainaccs = []\r\n",
        "testaccs = []\r\n",
        "losses = []\r\n",
        "nonzerowts = []\r\n",
        "\r\n",
        "for e in range(1):\r\n",
        "  tot_loss = 0.0\r\n",
        "  iv=0\r\n",
        "\r\n",
        "  for i, data in enumerate(mnist_loader,0):\r\n",
        "    inputs, labels = data\r\n",
        "   # inputs, labels = inputs.cuda(), labels.cuda() # add this line if using GPU\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    outputs = model_alex(inputs) #change to model_vgg for vgg\r\n",
        "    #print(outputs)\r\n",
        "    loss = criterion(outputs, labels)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    tot_loss += loss.item()\r\n",
        "    iv+=1\r\n",
        "    # if(i>100):\r\n",
        "    #   break\r\n",
        "  print('[%d, %5d] loss: %.3f' %(e + 1, i + 1, tot_loss /iv))\r\n",
        "  losses.append(tot_loss/iv)\r\n",
        "  trainaccs.append(findacc(mnist_loader,model_alex))\r\n",
        "  testaccs.append(findacc(mnist_test_loader,model_alex))\r\n",
        "  zeros = 0\r\n",
        "  allz = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HC4Oxh2fqnq"
      },
      "source": [
        "findacc(mnist_test_loader,model_alex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cko1QA3RQbxg"
      },
      "source": [
        "# import matplotlib.pyplot as plt\r\n",
        "# modelstr = \"Alexnet\"\r\n",
        "\r\n",
        "# plt.plot(range(epoch),trainaccs,label=\"train accuracy\")\r\n",
        "# plt.plot(range(epoch),testaccs,label=\"test accuracy\")\r\n",
        "# plt.title(modelstr+  \", cross entropy,adam\")\r\n",
        "# plt.ylabel(\"Accuracies\")\r\n",
        "# plt.xlabel(\"Epochs\")\r\n",
        "# plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UHTneFKY2JT"
      },
      "source": [
        "# plt.clf()\r\n",
        "# plt.plot(range(len(losses)),losses)\r\n",
        "# # plt.plot(range(epoch),testaccs,label=\"test accuracy\")\r\n",
        "# plt.title(modelstr+ \", cross entropy, adam\")\r\n",
        "# plt.ylabel(\"Loss\")\r\n",
        "# plt.xlabel(\"Epochs\")\r\n",
        "# # plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}